{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2aUJQoxaQmY"
      },
      "source": [
        "# ğŸŒ Mwalimu-LangLearn: Interactive Language Learning Tool with Gemma 3n\n",
        "\n",
        "**An Educational Tool for Multilingual Language Learning using Google's Gemma 3n**\n",
        "\n",
        "---\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook builds an interactive language learning application powered by **Google's Gemma 3n** model. The app leverages Gemma 3n's multimodal capabilities (text + image) and multilingual support (140+ languages) to create a comprehensive language learning experience.\n",
        "\n",
        "### Features:\n",
        "1. **ğŸ“ Writing Exercise Feedback** â€” Real-time grammar, vocabulary, and style correction\n",
        "2. **ğŸ–¼ï¸ Visual Object Recognition** â€” Upload images to identify objects and learn translations\n",
        "3. **ğŸ”„ Translation Practice** â€” Translate sentences and get detailed feedback\n",
        "4. **ğŸ“š Vocabulary Builder** â€” Generate contextual vocabulary lessons\n",
        "5. **ğŸ’¬ Conversation Practice** â€” Simulate dialogues in the target language\n",
        "\n",
        "### Why Gemma 3n?\n",
        "- **Compact & Efficient**: E2B (effective 2B params) or E4B (effective 4B params) â€” runs on Kaggle free GPUs\n",
        "- **Multimodal**: Handles text + images natively (MobileNet-V5 vision encoder)\n",
        "- **Multilingual**: Trained on 140+ languages â€” perfect for African language contexts\n",
        "- **On-device ready**: Designed for edge deployment (phones, tablets)\n",
        "\n",
        "### Architecture\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                 Gradio Interface                  â”‚\n",
        "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
        "â”‚  â”‚ Writing  â”‚  Visual  â”‚ Translateâ”‚  Vocab    â”‚  â”‚\n",
        "â”‚  â”‚ Feedback â”‚  Learn   â”‚ Practice â”‚  Builder  â”‚  â”‚\n",
        "â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â”‚\n",
        "â”‚       â”‚          â”‚          â”‚           â”‚        â”‚\n",
        "â”‚  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”   â”‚\n",
        "â”‚  â”‚        Gemma 3n E2B/E4B (Instruct)        â”‚   â”‚\n",
        "â”‚  â”‚   AutoModelForImageTextToText + Processor  â”‚   â”‚\n",
        "â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚\n",
        "â”‚  â”‚   â”‚  Text   â”‚  â”‚  Vision  â”‚  â”‚  Audio  â”‚ â”‚   â”‚\n",
        "â”‚  â”‚   â”‚ Decoder â”‚  â”‚ Encoder  â”‚  â”‚ Encoder â”‚ â”‚   â”‚\n",
        "â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚\n",
        "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**Author**: Pascal Burume Buhendwa  \n",
        "**Environment**: Kaggle Notebook (GPU T4 x2 or P100)  \n",
        "**Model**: Google Gemma 3n E2B-IT (Instruction Tuned)  \n",
        "**Framework**: HuggingFace Transformers + Gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oafBmoXIaQma"
      },
      "source": [
        "---\n",
        "## Step 1: Environment Setup & Dependencies\n",
        "\n",
        "We need to install the latest versions of key libraries:\n",
        "- **transformers** (â‰¥4.53.0) â€” Required for Gemma 3n support\n",
        "- **timm** â€” For the MobileNet-V5 vision encoder\n",
        "- **accelerate** â€” For efficient model loading with `device_map=\"auto\"`\n",
        "- **gradio** â€” For the interactive web interface\n",
        "- **kagglehub** â€” To download models from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYxR-4pnaQma",
        "outputId": "c3e2f739-f8f2-4e2e-bfd8-2d39f2bf78d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-26.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-26.0.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-26.0.1\n",
            "âœ… All dependencies installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# STEP 1: Install Dependencies\n",
        "# ============================================================\n",
        "# Install the latest transformers (Gemma 3n requires >=4.53.0)\n",
        "!pip install -q git+https://github.com/huggingface/transformers.git\n",
        "\n",
        "# Install timm for vision encoder (MobileNet-V5)\n",
        "!pip install -q timm --upgrade\n",
        "\n",
        "# Install accelerate for efficient model distribution\n",
        "!pip install -q accelerate\n",
        "\n",
        "# Install Gradio for the interactive UI\n",
        "!pip install -q gradio\n",
        "\n",
        "# Install kagglehub for model download\n",
        "!pip install -q kagglehub\n",
        "\n",
        "# Install Pillow for image handling\n",
        "!pip install -q Pillow\n",
        "\n",
        "# Install Update\n",
        "!pip install --upgrade pip\n",
        "\n",
        "print(\"âœ… All dependencies installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGg8mN9caQmb"
      },
      "source": [
        "---\n",
        "## Step 2: Import Libraries\n",
        "\n",
        "Import all required Python packages. Key classes:\n",
        "- `AutoProcessor` â€” Handles tokenization for both text and image inputs\n",
        "- `AutoModelForImageTextToText` â€” The multimodal Gemma 3n model class\n",
        "- `kagglehub.model_download` â€” Downloads model weights from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjH4SNCBaQmb",
        "outputId": "f819d8fd-9231-43aa-c210-d5206c57d366"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.9.0+cu128\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "GPU Memory: 15.6 GB\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# STEP 2: Import Libraries\n",
        "# ============================================================\n",
        "import os\n",
        "import torch\n",
        "import kagglehub\n",
        "import gradio as gr\n",
        "from time import time\n",
        "from PIL import Image\n",
        "from transformers import (\n",
        "    AutoProcessor,\n",
        "    AutoModelForImageTextToText,\n",
        ")\n",
        "\n",
        "# Check GPU availability\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"âš ï¸ No GPU detected. Model will run on CPU (much slower).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBZyb_l7aQmc"
      },
      "source": [
        "---\n",
        "## Step 3: Download and Load the Gemma 3n Model\n",
        "\n",
        "### How the model loading works:\n",
        "\n",
        "1. **`kagglehub.model_download()`** downloads the model weights from Kaggle's model hub to a local cache\n",
        "2. **`AutoProcessor.from_pretrained()`** loads the tokenizer + image processor that converts raw text/images into tensors\n",
        "3. **`AutoModelForImageTextToText.from_pretrained()`** loads the actual model with:\n",
        "   - `torch_dtype=\"auto\"` â€” Automatically selects the best precision (bfloat16 on GPU)\n",
        "   - `device_map=\"auto\"` â€” Distributes model layers across available GPUs/CPU automatically\n",
        "\n",
        "### Model Variants:\n",
        "| Variant | Effective Params | Total Params | Best For |\n",
        "|---------|-----------------|-------------|----------|\n",
        "| `gemma-3n-e2b-it` | 2B | ~6B | Kaggle free GPU, fast inference |\n",
        "| `gemma-3n-e4b-it` | 4B | ~8B | Better quality, needs more VRAM |\n",
        "\n",
        "We use **E2B-IT** (instruction-tuned) for efficiency on Kaggle's free T4 GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iTYrDbAaQmc",
        "outputId": "badadd82-9f45-4883-a9e3-559a93e10794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.2.0.dev0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu128)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (26.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.3)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.12/dist-packages (from transformers) (0.23.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (3.21.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.23.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer->transformers) (8.3.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer->transformers) (13.9.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer->transformers) (0.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer->transformers) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer->transformers) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer->transformers) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install kagglehub transformers torch accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289,
          "referenced_widgets": [
            "1e890bedc1374d9eaee0e20cd1988103",
            "aa12c01488ca4ee6ab5a0f477ee22bda",
            "3e73829b68314933a9a154fca7421c9d",
            "66d19f10f2384e28be0871acc706d56c",
            "e433ee207e49447fb119fa7133c6fb35",
            "c31c53ad4e9e464b95ebb2475276dc14",
            "43817df852e94b3ba04c80a1523e06bf",
            "552612e5f98d4ab18d8957a2a58af688",
            "f1347cac04434209b324469818494388",
            "6eb9927d561b41c785f0b9574afa1b41",
            "28100b74c4354e139030700278882d12"
          ]
        },
        "id": "UfYj-12saQmc",
        "outputId": "bec1c1f5-a57a-46c6-81a7-f610d01790dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¥ Downloading Gemma 3n E2B-IT from Kaggle...\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (1.0.0).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (1.0.0).\n",
            "Downloading from https://www.kaggle.com/api/v1/models/google/gemma-3n/transformers/gemma-3n-e2b-it/2/download...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16.0G/16.0G [03:42<00:00, 76.9MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Model downloaded to: /root/.cache/kagglehub/models/google/gemma-3n/transformers/gemma-3n-e2b-it/2\n",
            "ğŸ”§ Loading processor...\n",
            "ğŸ§  Loading model (this may take 2-5 minutes)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e890bedc1374d9eaee0e20cd1988103",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/1556 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Model loaded successfully!\n",
            "   Device: cuda:0\n",
            "   Dtype: torch.bfloat16\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import kagglehub\n",
        "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
        "\n",
        "# Set your Kaggle credentials (these are the correct ones!)\n",
        "os.environ['KAGGLE_USERNAME'] = 'Your Kaggle Username'\n",
        "os.environ['KAGGLE_KEY'] = 'Your Kaggle API Key'\n",
        "\n",
        "print(\"ğŸ“¥ Downloading Gemma 3n E2B-IT from Kaggle...\")\n",
        "GEMMA_PATH = kagglehub.model_download(\n",
        "    \"google/gemma-3n/transformers/gemma-3n-e2b-it\"\n",
        ")\n",
        "print(f\"âœ… Model downloaded to: {GEMMA_PATH}\")\n",
        "\n",
        "# Load the processor\n",
        "print(\"ğŸ”§ Loading processor...\")\n",
        "processor = AutoProcessor.from_pretrained(GEMMA_PATH)\n",
        "\n",
        "# Load the model\n",
        "print(\"ğŸ§  Loading model (this may take 2-5 minutes)...\")\n",
        "model = AutoModelForImageTextToText.from_pretrained(\n",
        "    GEMMA_PATH,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "print(f\"âœ… Model loaded successfully!\")\n",
        "print(f\"   Device: {model.device}\")\n",
        "print(f\"   Dtype: {model.dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7ECu6qFaQmc"
      },
      "source": [
        "---\n",
        "## Step 4: Core Inference Functions\n",
        "\n",
        "We build two core functions:\n",
        "\n",
        "### 4a. `query_model()` â€” Text-only inference\n",
        "This function:\n",
        "1. Constructs a **chat-template** message with system + user roles\n",
        "2. Applies the chat template via `processor.apply_chat_template()`\n",
        "3. Tokenizes and sends to model device\n",
        "4. Generates response with `model.generate()`\n",
        "5. Decodes and extracts only the assistant's response\n",
        "\n",
        "### 4b. `query_model_with_image()` â€” Multimodal inference (text + image)\n",
        "This function:\n",
        "1. Opens and preprocesses the image via PIL\n",
        "2. Constructs a message with an `{\"type\": \"image\"}` content block\n",
        "3. The processor automatically resizes the image to 256/512/768px and encodes it to 256 tokens\n",
        "4. Both image and text tokens are sent to the model together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQDWAojdaQmc",
        "outputId": "575f1c97-68ff-41a9-cef5-dcd19e897a20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ§ª Testing text-only inference...\n",
            "   Response: model\n",
            "Bonjour, comment allez-vous? \n",
            "\n",
            "(Formal)\n",
            "\n",
            "or\n",
            "\n",
            "Salut, comment vas-tu? \n",
            "\n",
            "(Informal)\n",
            "   Time: 10.6s\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# STEP 4: Core Inference Functions\n",
        "# ============================================================\n",
        "\n",
        "def query_model(prompt, system_prompt=None, max_new_tokens=512):\n",
        "    \"\"\"\n",
        "    Send a text-only query to Gemma 3n using chat template format.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): The user's question or instruction\n",
        "        system_prompt (str): Optional system instruction for the model\n",
        "        max_new_tokens (int): Maximum length of generated response\n",
        "\n",
        "    Returns:\n",
        "        tuple: (response_text, execution_time_seconds)\n",
        "    \"\"\"\n",
        "    start_time = time()\n",
        "\n",
        "    # Build the conversation messages\n",
        "    messages = []\n",
        "    if system_prompt:\n",
        "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
        "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "    # Apply chat template â€” this adds special tokens like <start_of_turn>\n",
        "    input_text = processor.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    # Tokenize and move to model device\n",
        "    inputs = processor(\n",
        "        text=input_text,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(model.device, dtype=model.dtype)\n",
        "\n",
        "    # Generate response\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            disable_compile=True,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "        )\n",
        "\n",
        "    # Decode the full output\n",
        "    full_text = processor.batch_decode(\n",
        "        outputs,\n",
        "        skip_special_tokens=True,\n",
        "        clean_up_tokenization_spaces=True\n",
        "    )[0]\n",
        "\n",
        "    # Extract only the assistant's response (after the prompt)\n",
        "    # The model echoes the input, so we split on the last user message\n",
        "    response = full_text.split(prompt)[-1].strip()\n",
        "\n",
        "    total_time = round(time() - start_time, 2)\n",
        "    return response, total_time\n",
        "\n",
        "\n",
        "def query_model_with_image(image, prompt, system_prompt=None, max_new_tokens=512):\n",
        "    \"\"\"\n",
        "    Send a multimodal query (image + text) to Gemma 3n.\n",
        "\n",
        "    The vision encoder (MobileNet-V5) processes the image at\n",
        "    256x256, 512x512, or 768x768 resolution, encoding it to 256 tokens.\n",
        "\n",
        "    Args:\n",
        "        image: PIL Image or file path\n",
        "        prompt (str): Text instruction about the image\n",
        "        system_prompt (str): Optional system instruction\n",
        "        max_new_tokens (int): Maximum response length\n",
        "\n",
        "    Returns:\n",
        "        tuple: (response_text, execution_time_seconds)\n",
        "    \"\"\"\n",
        "    start_time = time()\n",
        "\n",
        "    # Ensure we have a PIL Image\n",
        "    if isinstance(image, str):\n",
        "        image = Image.open(image)\n",
        "    if image.mode != \"RGB\":\n",
        "        image = image.convert(\"RGB\")\n",
        "\n",
        "    # Build multimodal messages with image content block\n",
        "    messages = []\n",
        "    if system_prompt:\n",
        "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
        "\n",
        "    messages.append({\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\", \"image\": image},  # Image content block\n",
        "            {\"type\": \"text\", \"text\": prompt},    # Text instruction\n",
        "        ]\n",
        "    })\n",
        "\n",
        "    # Apply chat template\n",
        "    input_text = processor.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    # Process both text and image together\n",
        "    inputs = processor(\n",
        "        text=input_text,\n",
        "        images=image,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(model.device, dtype=model.dtype)\n",
        "\n",
        "    # Generate response\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            disable_compile=True,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "        )\n",
        "\n",
        "    # Decode response\n",
        "    full_text = processor.batch_decode(\n",
        "        outputs,\n",
        "        skip_special_tokens=True,\n",
        "        clean_up_tokenization_spaces=True\n",
        "    )[0]\n",
        "\n",
        "    # Extract assistant response\n",
        "    response = full_text.split(prompt)[-1].strip()\n",
        "\n",
        "    total_time = round(time() - start_time, 2)\n",
        "    return response, total_time\n",
        "\n",
        "\n",
        "# Quick test\n",
        "print(\"ğŸ§ª Testing text-only inference...\")\n",
        "test_response, test_time = query_model(\n",
        "    \"Translate 'Hello, how are you?' to French.\",\n",
        "    system_prompt=\"You are a helpful language tutor. Be concise.\"\n",
        ")\n",
        "print(f\"   Response: {test_response}\")\n",
        "print(f\"   Time: {test_time}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N19sjC-_aQmd"
      },
      "source": [
        "---\n",
        "## Step 5: Language Learning Feature Functions\n",
        "\n",
        "Each function maps to a specific learning mode in the app. They all use the core `query_model()` or `query_model_with_image()` functions but with specialized system prompts that instruct Gemma 3n to act as a language tutor.\n",
        "\n",
        "### Supported Language Pairs:\n",
        "Gemma 3n supports 140+ languages. Key languages for our context:\n",
        "- **English** â†” **French** (DRC official language)\n",
        "- **English** â†” **Swahili** (Eastern DRC lingua franca)\n",
        "- **French** â†” **Japanese** (for ABE Initiative students)\n",
        "- **English** â†” **Lingala** (Western DRC lingua franca)\n",
        "- And many more..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lnE-SOKaQmd",
        "outputId": "5034018e-4757-4524-dae1-205639b58c5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… All feature functions defined!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# STEP 5: Language Learning Feature Functions\n",
        "# ============================================================\n",
        "\n",
        "# Available target languages\n",
        "LANGUAGES = [\n",
        "    \"French\", \"Swahili\", \"Japanese\", \"English\", \"Lingala\",\n",
        "    \"Spanish\", \"Portuguese\", \"Arabic\", \"Chinese (Mandarin)\",\n",
        "    \"German\", \"Korean\", \"Hindi\", \"Italian\", \"Russian\"\n",
        "]\n",
        "\n",
        "PROFICIENCY_LEVELS = [\"Beginner (A1-A2)\", \"Intermediate (B1-B2)\", \"Advanced (C1-C2)\"]\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# FEATURE 1: Writing Exercise Feedback\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def writing_feedback(text, target_language, proficiency_level):\n",
        "    \"\"\"\n",
        "    Analyze written text in the target language and provide\n",
        "    grammar corrections, vocabulary suggestions, and style tips.\n",
        "    \"\"\"\n",
        "    if not text.strip():\n",
        "        return \"âš ï¸ Please enter some text to analyze.\", \"\"\n",
        "\n",
        "    system_prompt = f\"\"\"You are an expert {target_language} language tutor.\n",
        "The student's proficiency level is {proficiency_level}.\n",
        "Analyze their writing and provide:\n",
        "1. **Corrections**: Fix grammar, spelling, and syntax errors. Show the corrected version.\n",
        "2. **Explanations**: Explain each error briefly so the student learns.\n",
        "3. **Vocabulary**: Suggest better word choices or useful alternatives.\n",
        "4. **Style Tips**: Provide natural phrasing suggestions.\n",
        "5. **Score**: Give a score out of 10 with encouragement.\n",
        "Be encouraging and supportive. Use examples when helpful.\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"Please review and correct this {target_language} text written by a {proficiency_level} student:\n",
        "\n",
        "\\\"\\\"\\\"\n",
        "{text}\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "Provide detailed feedback with corrections and explanations.\"\"\"\n",
        "\n",
        "    response, exec_time = query_model(prompt, system_prompt, max_new_tokens=1024)\n",
        "    return response, f\"â±ï¸ Response time: {exec_time}s\"\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# FEATURE 2: Visual Object Recognition & Translation\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def visual_learning(image, target_language, source_language=\"English\"):\n",
        "    \"\"\"\n",
        "    Identify objects in an uploaded image and provide translations\n",
        "    with pronunciation guides and example sentences.\n",
        "    \"\"\"\n",
        "    if image is None:\n",
        "        return \"âš ï¸ Please upload an image.\", \"\"\n",
        "\n",
        "    system_prompt = f\"\"\"You are a visual language learning assistant.\n",
        "Help students learn {target_language} vocabulary through images.\n",
        "Be thorough but organized in your responses.\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"Look at this image carefully. Please:\n",
        "\n",
        "1. **Identify** all major objects, people, and elements visible in the image.\n",
        "2. **Translate** each identified item from {source_language} to {target_language}.\n",
        "3. **Pronunciation**: Include pronunciation guide for each {target_language} word.\n",
        "4. **Example Sentences**: Write 2-3 simple sentences in {target_language} using these vocabulary words.\n",
        "5. **Cultural Note**: If relevant, share any cultural context about these items in {target_language}-speaking regions.\n",
        "\n",
        "Format the response clearly with sections.\"\"\"\n",
        "\n",
        "    response, exec_time = query_model_with_image(\n",
        "        image, prompt, system_prompt, max_new_tokens=1024\n",
        "    )\n",
        "    return response, f\"â±ï¸ Response time: {exec_time}s\"\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# FEATURE 3: Translation Practice with Feedback\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def translation_practice(original_text, student_translation, source_lang, target_lang, proficiency):\n",
        "    \"\"\"\n",
        "    The student translates a sentence, and the model provides\n",
        "    detailed feedback comparing their translation to an ideal one.\n",
        "    \"\"\"\n",
        "    if not original_text.strip() or not student_translation.strip():\n",
        "        return \"âš ï¸ Please provide both the original text and your translation.\", \"\"\n",
        "\n",
        "    system_prompt = f\"\"\"You are a professional {source_lang}-to-{target_lang} translation tutor.\n",
        "The student's level is {proficiency}. Be encouraging but thorough.\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"A {proficiency} student was asked to translate this from {source_lang} to {target_lang}:\n",
        "\n",
        "**Original ({source_lang}):** \\\"{original_text}\\\"\n",
        "**Student's Translation ({target_lang}):** \\\"{student_translation}\\\"\n",
        "\n",
        "Please provide:\n",
        "1. **Your ideal translation** of the original text\n",
        "2. **Accuracy score** (1-10)\n",
        "3. **Specific corrections** â€” What did the student get wrong?\n",
        "4. **What they got right** â€” Praise good parts\n",
        "5. **Grammar notes** â€” Key grammar rules they should review\n",
        "6. **Alternative translations** â€” Other valid ways to translate this\"\"\"\n",
        "\n",
        "    response, exec_time = query_model(prompt, system_prompt, max_new_tokens=1024)\n",
        "    return response, f\"â±ï¸ Response time: {exec_time}s\"\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# FEATURE 4: Vocabulary Builder\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def vocabulary_builder(topic, target_language, proficiency, num_words=10):\n",
        "    \"\"\"\n",
        "    Generate a themed vocabulary lesson with words, translations,\n",
        "    example sentences, and a mini-quiz.\n",
        "    \"\"\"\n",
        "    if not topic.strip():\n",
        "        return \"âš ï¸ Please enter a topic.\", \"\"\n",
        "\n",
        "    system_prompt = f\"\"\"You are a {target_language} vocabulary tutor.\n",
        "Create engaging vocabulary lessons appropriate for {proficiency} learners.\n",
        "Make learning fun and memorable.\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"Create a vocabulary lesson about \\\"{topic}\\\" in {target_language} for a {proficiency} student.\n",
        "\n",
        "Include:\n",
        "1. **{num_words} Key Words**: Each with translation, pronunciation, and part of speech\n",
        "2. **Example Sentences**: One sentence per word showing it in context\n",
        "3. **Common Phrases**: 3-5 useful phrases related to the topic\n",
        "4. **Mini Quiz**: 3 fill-in-the-blank questions to test the vocabulary\n",
        "5. **Memory Tips**: Mnemonics or tricks to remember difficult words\"\"\"\n",
        "\n",
        "    response, exec_time = query_model(prompt, system_prompt, max_new_tokens=1500)\n",
        "    return response, f\"â±ï¸ Response time: {exec_time}s\"\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# FEATURE 5: Conversation Practice\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def conversation_practice(user_message, scenario, target_language, proficiency, chat_history=\"\"):\n",
        "    \"\"\"\n",
        "    Simulate a conversation in the target language.\n",
        "    The model plays a character and provides corrections inline.\n",
        "    \"\"\"\n",
        "    if not user_message.strip():\n",
        "        return \"âš ï¸ Please type a message to continue the conversation.\", \"\", \"\"\n",
        "\n",
        "    system_prompt = f\"\"\"You are a friendly conversation partner helping a {proficiency} student\n",
        "practice {target_language}. The scenario is: {scenario}.\n",
        "\n",
        "Rules:\n",
        "- Respond naturally IN {target_language}\n",
        "- After your response, add a section called \"ğŸ“ Language Notes:\" where you:\n",
        "  * Correct any errors in the student's message\n",
        "  * Explain grammar points\n",
        "  * Suggest more natural ways to say things\n",
        "- Keep the conversation going by asking a follow-up question\n",
        "- Adjust complexity to {proficiency} level\"\"\"\n",
        "\n",
        "    # Include chat history for context\n",
        "    prompt = f\"\"\"{f'Previous conversation:{chr(10)}{chat_history}{chr(10)}{chr(10)}' if chat_history else ''}Student says: \\\"{user_message}\\\"\n",
        "\n",
        "Respond in character (in {target_language}), then provide language notes.\"\"\"\n",
        "\n",
        "    response, exec_time = query_model(prompt, system_prompt, max_new_tokens=768)\n",
        "\n",
        "    # Update chat history\n",
        "    updated_history = f\"{chat_history}\\nStudent: {user_message}\\nTutor: {response}\"\n",
        "\n",
        "    return response, updated_history, f\"â±ï¸ Response time: {exec_time}s\"\n",
        "\n",
        "\n",
        "print(\"âœ… All feature functions defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqKwU_aLaQmd"
      },
      "source": [
        "---\n",
        "## Step 6: Quick Feature Tests (Before Building UI)\n",
        "\n",
        "Let's verify each feature works before building the Gradio interface."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7ir16OfaQmd",
        "outputId": "223a5ad7-834e-4878-b647-68018896dc3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "TEST 1: Writing Feedback (French)\n",
            "============================================================\n",
            "model\n",
            "Bonjour! C'est trÃ¨s bien que tu aies Ã©crit ce court texte en franÃ§ais, c'est un excellent dÃ©but!  It's great that you're practicing!  Let's take a look at it and see how we can make it even better.\n",
            "\n",
            "Here's the analysis and corrections:\n",
            "\n",
            "**Original Text:**\n",
            "\n",
            "\"\"\"\n",
            "Je suis allÃ© au magazin pour acheter du pain. Le pain Ã©tait trÃ¨s bon et je mange beaucoup.\n",
            "\"\"\"\n",
            "\n",
            "**Corrected Text:**\n",
            "\n",
            "\"\"\"\n",
            "Je suis allÃ© au magasin pour acheter du pain. Le pain Ã©tait trÃ¨s bon, et je mange beaucoup.\n",
            "\"\"\"\n",
            "\n",
            "**1. Corrections:**\n",
            "\n",
            "*   **\"magazin\" changed to \"magasin\"**:  \"Magasin\" is the correct form of the word for \"shop\" or \"store\" in French.  \"Magazin\" is a misspelling.\n",
            "*   **Added a comma after \"bon\"**:  The sentence is a simple statement, and a comma is needed to separate the two independent clauses (\"Le pain Ã©tait trÃ¨s bon\" and \"je mange beaucoup\").\n",
            "\n",
            "**2. Explanations:**\n",
            "\n",
            "*   **Spelling:**  The most obvious error was the misspelling of \"magasin.\"  Pay attention to spelling!  It's a common mistake for learners.\n",
            "*   **Punctuation:** Commas are crucial in French for clarity.  They help to separate ideas and make your writing easier to understand.  Think of them as little pauses in the flow of your sentences.  The comma after \"bon\" creates a natural pause.\n",
            "\n",
            "**3. Vocabulary:**\n",
            "\n",
            "*   While \"beaucoup\" (a lot) is perfectly acceptable, you could consider alternatives for a slightly more sophisticated tone.  Here are a few:\n",
            "    *   \"Je mange Ã©normÃ©ment\" (I eat enormously)\n",
            "    *   \"Je mange trÃ¨s souvent\" (I eat very often)\n",
            "    *   \"Je mange rÃ©guliÃ¨rement\" (I eat regularly)\n",
            "\n",
            "**4. Style Tips:**\n",
            "\n",
            "*   The sentence is a little simple.  You could add a bit more detail.  For example: \"Je suis allÃ© au magasin pour acheter du pain frais.  Le pain Ã©tait trÃ¨s bon, et je mange beaucoup de pain Ã  la maison.\" (I went to the shop to buy fresh bread. The bread was very good, and I eat a lot of bread at home.)  Adding a little more description makes your writing more engaging.\n",
            "*   Instead of \"je mange beaucoup\", you could say \"Je suis un grand mangeur de pain\" (I am a big bread eater) â€“ a bit more idiomatic!\n",
            "\n",
            "**5. Score:**\n",
            "\n",
            "I'd give your text a **7/10**.  You've grasped the basic sentence structure and have a good understanding of vocabulary. The main error was a simple spelling mistake.  This is a great foundation for continuing to improve your French writing! Keep practicing, and don't be afraid to make mistakes â€“ that's how we learn!\n",
            "\n",
            "**Encouragement:**\n",
            "\n",
            "Excellent effort! You are making great progress. Keep practicing and don't hesitate to ask if you have more questions.  You're doing really well!  Let's continue working on expanding your vocabulary and sentence complexity.  N'hÃ©sitez pas Ã  continuer! (Don't hesitate to continue!)\n",
            "â±ï¸ Response time: 110.89s\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# STEP 6: Test Each Feature\n",
        "# ============================================================\n",
        "\n",
        "# Test 1: Writing Feedback (French)\n",
        "print(\"=\"*60)\n",
        "print(\"TEST 1: Writing Feedback (French)\")\n",
        "print(\"=\"*60)\n",
        "result, timing = writing_feedback(\n",
        "    \"Je suis allÃ© au magazin pour acheter du pain. Le pain Ã©tait trÃ¨s bon et je mange beaucoup.\",\n",
        "    \"French\",\n",
        "    \"Intermediate (B1-B2)\"\n",
        ")\n",
        "print(result)\n",
        "print(timing)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6P-crNlaQmd",
        "outputId": "fb5d3180-89a9-4e7a-f618-3010cc6604a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "TEST 2: Vocabulary Builder (Swahili)\n",
            "============================================================\n",
            "model\n",
            "## Swahili Vocabulary Lesson: Food and Cooking (A1-A2)\n",
            "\n",
            "**Welcome, mwanafunzi! (Student!)**  Let's learn some Swahili words about food and cooking!  This lesson will help you understand what people say when talking about what they eat and how they prepare it.  Let's have fun!\n",
            "\n",
            "**1. Key Words:**\n",
            "\n",
            "| **Swahili Word** | **Translation** | **Pronunciation** | **Part of Speech** |\n",
            "|---|---|---|---|\n",
            "| **chakula** | food | cha-ku-la | Noun (general term for food) |\n",
            "| **chakula chakupikia** | cooking food | cha-ku-la cha-ku-pi-kia | Noun (food used for cooking) |\n",
            "| **nyama** | meat | na-ma | Noun (meat) |\n",
            "| **lazima** | must/have to | la-zi-ma | Adverb (must/have to) |\n",
            "| **kupika** | to cook | ku-pi-ka | Verb (to cook) |\n",
            "\n",
            "**2. Example Sentences:**\n",
            "\n",
            "*   **chakula:**  \"Ninapenda chakula cha safi.\" (I like clean food.)\n",
            "*   **chakula chakupikia:** \"Tunapika chakula cha kupikia kwa nyama.\" (We cook food for cooking with meat.)\n",
            "*   **nyama:** \"Mimi ninapenda nyama ya ng'ombe.\" (I like beef.)\n",
            "*   **lazima:** \"Lazima nipike chakula chakupikia.\" (I must cook food for cooking.)\n",
            "*   **kupika:** \"Ninapenda kupika chakula.\" (I like to cook food.)\n",
            "\n",
            "**3. Common Phrases:**\n",
            "\n",
            "*   **\"Samahani, una chakula?\"** (Excuse me, do you have food?) - *Very useful for asking if someone has something to eat!*\n",
            "*   **\"Nimepika chakula.\"** (I have cooked food.) - *A simple way to say you've cooked something.*\n",
            "*   **\"Tunaweza kupika nini?\"** (What can we cook?) - *Good for planning a meal.*\n",
            "*   **\"Hili ni chakula chake.\"** (This is his/her food.) - *Useful for pointing out someone's meal.*\n",
            "*   **\"Nahitaji chakula.\"** (I need food.) - *Useful if you are hungry!*\n",
            "\n",
            "**4. Mini Quiz:**\n",
            "\n",
            "1.  **I need to _________ food for dinner.** (fill in the blank)\n",
            "    *   a) kula (to eat)\n",
            "    *   b) kupika (to cook)\n",
            "    *   c) kuona (to see)\n",
            "    *   d) kuenda (to go)\n",
            "    **Answer: b) kupika**\n",
            "\n",
            "2.  **She likes to cook _________.** (fill in the blank)\n",
            "    *   a) chakula\n",
            "    *   b) nyama\n",
            "    *   c) chakula chakupikia\n",
            "    *   d) chakula chake\n",
            "    **Answer: c) chakula chakupikia**\n",
            "\n",
            "3.  **We _________ meat for the stew.** (fill in the blank)\n",
            "    *   a) kula\n",
            "    *   b) kupika\n",
            "    *   c) nyama\n",
            "    *   d) chakula\n",
            "    **Answer: c) nyama**\n",
            "\n",
            "**5. Memory Tips:**\n",
            "\n",
            "*   **Chakula:** Imagine a big plate of food â€“ that's what \"chakula\" means!  Think of it as the general idea of all the food.\n",
            "*   **Chakula chakupikia:**  Think of it as the ingredients you use *to make* food. It's the \"cooking food\" part.\n",
            "*   **Nyama:**  Picture a juicy piece of meat â€“ that's what \"nyama\" represents.\n",
            "*   **Lazima:**  Think of \"lazima\" as a strong \"must.\" Itâ€™s like saying \"I have to!\"\n",
            "*   **Kupika:**  Imagine you are stirring something in a pot â€“ thatâ€™s what \"kupika\" means!\n",
            "\n",
            "**Practice Time!**\n",
            "\n",
            "Try to use these words in simple sentences.  You can practice with your family or friends!  \n",
            "\n",
            "**Jambo! (Hello!)  Karibu! (Welcome!)  Good luck!**\n",
            "\n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "**Further Practice Ideas:**\n",
            "\n",
            "*   **Flashcards:** Create flashcards with the Swahili word on one side and the English translation on the other.\n",
            "*   **Drawing:** Draw pictures of food and cooking items and label them in Swahili.\n",
            "*   **Role-Playing:** Practice ordering food at a restaurant or asking for ingredients.\n",
            "*   **Online Resources:** Use online Swahili dictionaries and vocabulary websites.\n",
            "â±ï¸ Response time: 153.23s\n"
          ]
        }
      ],
      "source": [
        "# Test 2: Vocabulary Builder (Swahili)\n",
        "print(\"=\"*60)\n",
        "print(\"TEST 2: Vocabulary Builder (Swahili)\")\n",
        "print(\"=\"*60)\n",
        "result, timing = vocabulary_builder(\n",
        "    \"Food and Cooking\",\n",
        "    \"Swahili\",\n",
        "    \"Beginner (A1-A2)\",\n",
        "    num_words=5\n",
        ")\n",
        "print(result)\n",
        "print(timing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWwgJDsqaQmd",
        "outputId": "51fd1804-a439-4832-9cb3-83281662e73c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "TEST 3: Translation Practice (English â†’ Japanese)\n",
            "============================================================\n",
            "model\n",
            "Okay, let's take a look at your translation! You've done a great job! Here's a breakdown to help you understand and improve.\n",
            "\n",
            "**1. Ideal Translation:**\n",
            "\n",
            "The most natural and common way to say this in Japanese would be:\n",
            "\n",
            "**ä»Šæ—¥ã¯ã„ã„å¤©æ°—ã ã‹ã‚‰ã€æ•£æ­©ã«è¡ŒããŸã„ãªã€‚**\n",
            "(Kyou wa ii tenki dakara, sanpo ni ikitai na.)\n",
            "\n",
            "*   `ä»Šæ—¥ã¯` (Kyou wa) - Today\n",
            "*   `ã„ã„å¤©æ°—` (ii tenki) - Good weather\n",
            "*   `ã ã‹ã‚‰` (dakara) - Because / Therefore\n",
            "*   `æ•£æ­©ã«` (sanpo ni) - For a walk (dative case)\n",
            "*   `è¡ŒããŸã„ãª` (ikitai na) - I want to go (a softer, more casual expression)\n",
            "\n",
            "**2. Accuracy Score:**\n",
            "\n",
            "I'd give your translation a **9/10**. It's very close and perfectly understandable!\n",
            "\n",
            "**3. Specific Corrections:**\n",
            "\n",
            "Your translation, \"ä»Šæ—¥ã®å¤©æ°—ã¯ã¨ã¦ã‚‚ã„ã„ã§ã™ã€‚æ•£æ­©ã«è¡ŒããŸã„ã§ã™ã€‚\" is grammatically correct and conveys the meaning. However, there's a slight difference in nuance.  The difference is in the *reason* for wanting to go for a walk.\n",
            "\n",
            "*   **\"ä»Šæ—¥ã®å¤©æ°—ã¯ã¨ã¦ã‚‚ã„ã„ã§ã™ã€‚\" (Kyou wa totemo ii desu.)** - \"Today the weather is very nice.\" This is a statement of fact.\n",
            "*   **\"æ•£æ­©ã«è¡ŒããŸã„ã§ã™ã€‚\" (Sanpo ni ikitai desu.)** - \"I want to go for a walk.\"  This is a statement of desire.\n",
            "\n",
            "The ideal translation adds a little more context, explaining *why* you want to go for a walk. The \"dakara\" (because/therefore) makes the connection between the weather and the desire to walk clearer.\n",
            "\n",
            "**4. What You Got Right:**\n",
            "\n",
            "*   **Correct sentence structure:** You've followed the basic sentence structure of Japanese well.\n",
            "*   **Correct vocabulary:** You used the correct vocabulary for \"weather\" (å¤©æ°— - tenki) and \"walk\" (æ•£æ­© - sanpo).\n",
            "*   **Polite form:**  Using \"ã§ã™\" (desu) makes it polite, which is good!\n",
            "\n",
            "**5. Grammar Notes:**\n",
            "\n",
            "*   **\"ã¯\" (wa):**  You used \"ä»Šæ—¥ã®å¤©æ°—ã¯\" (kyou no tenki wa), which is correct for stating the weather.  \"ã¯\" marks the topic of the sentence.\n",
            "*   **\"ã§ã™\" (desu):**  You used \"ã§ã™\" to make the sentence polite. This is appropriate for general conversation.\n",
            "*   **\"ï½ãŸã„\" (ï½tai):** This is a very common verb ending that expresses a desire or wish.  It's used with verbs like \"è¡Œã\" (iku - to go).\n",
            "*   **\"ã«\" (ni):** This particle indicates direction or purpose.  \"æ•£æ­©ã«\" (sanpo ni) means \"for a walk\" or \"to go for a walk.\"\n",
            "*   **\"ãª\" (na):** This adds a nuance of softness or a feeling.  It makes the sentence sound a little more casual and expresses a gentle desire.\n",
            "\n",
            "**6. Alternative Translations:**\n",
            "\n",
            "Here are a few other ways to say this, with slightly different nuances:\n",
            "\n",
            "*   **ä»Šæ—¥ã¯ã„ã„å¤©æ°—ã ã‹ã‚‰ã€æ•£æ­©ã—ãŸã„ãªã€‚** (Kyou wa ii tenki dakara, sanpo *shitai na*.) -  This is very similar to the ideal translation, but using \"ã—ãŸã„\" (shitai) instead of \"è¡ŒããŸã„\" (ikitai) gives it a slightly more direct feeling of wanting to do something.\n",
            "*   **ã„ã„å¤©æ°—ã§ã™ã­ã€‚æ•£æ­©ã«è¡ŒããŸã„ã§ã™ã€‚** (Ii tenki desu ne. Sanpo ni ikitai desu.) - \"It's nice weather, isn't it? I want to go for a walk.\"  This is a more conversational way to start.\n",
            "*   **ä»Šæ—¥ã¯ã„ã„å¤©æ°—ãªã®ã§ã€æ•£æ­©ã«è¡ŒããŸã„ã§ã™ã€‚** (Kyou wa ii tenki nano de, sanpo ni ikitai desu.) - \"Because it's nice weather today, I want to go for a walk.\" \"ãªã®ã§\" (nano de) is another way to express \"because.\"\n",
            "\n",
            "\n",
            "\n",
            "**Overall:**\n",
            "\n",
            "You're doing great!  Don't worry about the slight difference in nuance; it's a very natural way to express your desire. Keep practicing, and you'll become more comfortable with these concepts.  Feel free to ask if you have any more questions!  Let me know if you'd like to practice more sentences or work on other grammar points.\n",
            "â±ï¸ Response time: 142.74s\n"
          ]
        }
      ],
      "source": [
        "# Test 3: Translation Practice (English â†’ Japanese)\n",
        "print(\"=\"*60)\n",
        "print(\"TEST 3: Translation Practice (English â†’ Japanese)\")\n",
        "print(\"=\"*60)\n",
        "result, timing = translation_practice(\n",
        "    \"The weather is very nice today, I want to go for a walk.\",\n",
        "    \"ä»Šæ—¥ã®å¤©æ°—ã¯ã¨ã¦ã‚‚ã„ã„ã§ã™ã€‚æ•£æ­©ã«è¡ŒããŸã„ã§ã™ã€‚\",\n",
        "    \"English\",\n",
        "    \"Japanese\",\n",
        "    \"Beginner (A1-A2)\"\n",
        ")\n",
        "print(result)\n",
        "print(timing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zey8kj9raQmd"
      },
      "source": [
        "---\n",
        "## Step 7: Build the Gradio Interface\n",
        "\n",
        "Now we build the full interactive UI using **Gradio Blocks**. The interface has 5 tabs, one for each learning mode.\n",
        "\n",
        "### Gradio Architecture:\n",
        "- **`gr.Blocks`** â€” The main container for custom layouts\n",
        "- **`gr.Tabs`** â€” Creates a tabbed interface\n",
        "- **`gr.Row/Column`** â€” Layout controls\n",
        "- Each tab connects its button click to the corresponding feature function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qwi4Q-zaQme",
        "outputId": "8d8fea92-44b3-4da7-f85d-a5990f651346"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-797585069.py:20: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(\n",
            "/tmp/ipython-input-797585069.py:20: DeprecationWarning: The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "  with gr.Blocks(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Gradio interface built successfully!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# STEP 7: Build the Gradio Interface\n",
        "# ============================================================\n",
        "\n",
        "# Custom CSS for better styling\n",
        "custom_css = \"\"\"\n",
        ".gradio-container {\n",
        "    max-width: 1200px !important;\n",
        "}\n",
        ".feature-description {\n",
        "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "    color: white;\n",
        "    padding: 15px;\n",
        "    border-radius: 10px;\n",
        "    margin-bottom: 15px;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Build the interface\n",
        "with gr.Blocks(\n",
        "    title=\"ğŸŒ Mwalimu-LangLearn: AI Language Tutor\",\n",
        "    css=custom_css,\n",
        "    theme=gr.themes.Soft()\n",
        ") as demo:\n",
        "\n",
        "    # â”€â”€ Header â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    gr.Markdown(\"\"\"\n",
        "    # ğŸŒ Mwalimu-LangLearn: Interactive Language Learning Tool\n",
        "    ### Powered by Google Gemma 3n â€” Multilingual AI Tutor\n",
        "\n",
        "    Learn any of **140+ languages** with AI-powered feedback on writing,\n",
        "    visual vocabulary learning, translation practice, and more!\n",
        "\n",
        "    ---\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "\n",
        "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "        # TAB 1: Writing Feedback\n",
        "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "        with gr.TabItem(\"ğŸ“ Writing Feedback\", id=1):\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### âœï¸ Get AI Feedback on Your Writing\n",
        "            Write a paragraph in your target language and receive detailed\n",
        "            corrections, explanations, and improvement suggestions.\n",
        "            \"\"\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=1):\n",
        "                    writing_lang = gr.Dropdown(\n",
        "                        choices=LANGUAGES,\n",
        "                        value=\"French\",\n",
        "                        label=\"Target Language\"\n",
        "                    )\n",
        "                    writing_level = gr.Dropdown(\n",
        "                        choices=PROFICIENCY_LEVELS,\n",
        "                        value=\"Intermediate (B1-B2)\",\n",
        "                        label=\"Proficiency Level\"\n",
        "                    )\n",
        "                with gr.Column(scale=2):\n",
        "                    writing_input = gr.Textbox(\n",
        "                        label=\"Your Text\",\n",
        "                        placeholder=\"Write something in your target language...\",\n",
        "                        lines=6\n",
        "                    )\n",
        "\n",
        "            writing_btn = gr.Button(\"ğŸ“ Get Feedback\", variant=\"primary\")\n",
        "            writing_output = gr.Markdown(label=\"Feedback\")\n",
        "            writing_time = gr.Textbox(label=\"Performance\", interactive=False)\n",
        "\n",
        "            # Example inputs\n",
        "            gr.Examples(\n",
        "                examples=[\n",
        "                    [\"Je suis allÃ© au magazin hier pour acheter du pain. Le pain Ã©tait trÃ¨s bon et je mange beaucoup.\", \"French\", \"Intermediate (B1-B2)\"],\n",
        "                    [\"Ninajifunza Kiswahili kwa sababu ninapenda lugha ya Afrika. Mimi ni mwanafunzi mzuri.\", \"Swahili\", \"Beginner (A1-A2)\"],\n",
        "                    [\"ãã®ã†å‹é”ã¨ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ã«é£Ÿã¹ã¾ã—ãŸã€‚ã¨ã¦ã‚‚ç¾å‘³ã—ã„ã§ã—ãŸã€‚\", \"Japanese\", \"Beginner (A1-A2)\"],\n",
        "                ],\n",
        "                inputs=[writing_input, writing_lang, writing_level]\n",
        "            )\n",
        "\n",
        "            writing_btn.click(\n",
        "                fn=writing_feedback,\n",
        "                inputs=[writing_input, writing_lang, writing_level],\n",
        "                outputs=[writing_output, writing_time]\n",
        "            )\n",
        "\n",
        "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "        # TAB 2: Visual Learning (Image Recognition)\n",
        "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "        with gr.TabItem(\"ğŸ–¼ï¸ Visual Learning\", id=2):\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### ğŸ“¸ Learn Vocabulary Through Images\n",
        "            Upload any image â€” the AI will identify objects and teach you\n",
        "            their names in your target language with pronunciation and example sentences.\n",
        "            \"\"\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=1):\n",
        "                    visual_image = gr.Image(\n",
        "                        label=\"Upload an Image\",\n",
        "                        type=\"pil\",\n",
        "                        height=300\n",
        "                    )\n",
        "                    visual_target = gr.Dropdown(\n",
        "                        choices=LANGUAGES,\n",
        "                        value=\"French\",\n",
        "                        label=\"Learn Words In\"\n",
        "                    )\n",
        "                    visual_source = gr.Dropdown(\n",
        "                        choices=LANGUAGES,\n",
        "                        value=\"English\",\n",
        "                        label=\"Translate From\"\n",
        "                    )\n",
        "                    visual_btn = gr.Button(\"ğŸ” Identify & Translate\", variant=\"primary\")\n",
        "\n",
        "                with gr.Column(scale=2):\n",
        "                    visual_output = gr.Markdown(label=\"Visual Vocabulary\")\n",
        "                    visual_time = gr.Textbox(label=\"Performance\", interactive=False)\n",
        "\n",
        "            visual_btn.click(\n",
        "                fn=visual_learning,\n",
        "                inputs=[visual_image, visual_target, visual_source],\n",
        "                outputs=[visual_output, visual_time]\n",
        "            )\n",
        "\n",
        "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "        # TAB 3: Translation Practice\n",
        "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "        with gr.TabItem(\"ğŸ”„ Translation Practice\", id=3):\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### ğŸ”„ Practice Translating & Get Scored\n",
        "            Translate a sentence and the AI will compare your translation\n",
        "            to an ideal one, showing you exactly what to improve.\n",
        "            \"\"\")\n",
        "\n",
        "            with gr.Row():\n",
        "                trans_source_lang = gr.Dropdown(\n",
        "                    choices=LANGUAGES,\n",
        "                    value=\"English\",\n",
        "                    label=\"From Language\"\n",
        "                )\n",
        "                trans_target_lang = gr.Dropdown(\n",
        "                    choices=LANGUAGES,\n",
        "                    value=\"French\",\n",
        "                    label=\"To Language\"\n",
        "                )\n",
        "                trans_level = gr.Dropdown(\n",
        "                    choices=PROFICIENCY_LEVELS,\n",
        "                    value=\"Intermediate (B1-B2)\",\n",
        "                    label=\"Level\"\n",
        "                )\n",
        "\n",
        "            trans_original = gr.Textbox(\n",
        "                label=\"Original Text (to translate)\",\n",
        "                placeholder=\"Enter the text to translate...\",\n",
        "                lines=3\n",
        "            )\n",
        "            trans_student = gr.Textbox(\n",
        "                label=\"Your Translation\",\n",
        "                placeholder=\"Write your translation here...\",\n",
        "                lines=3\n",
        "            )\n",
        "\n",
        "            trans_btn = gr.Button(\"âœ… Check My Translation\", variant=\"primary\")\n",
        "            trans_output = gr.Markdown(label=\"Translation Feedback\")\n",
        "            trans_time = gr.Textbox(label=\"Performance\", interactive=False)\n",
        "\n",
        "            gr.Examples(\n",
        "                examples=[\n",
        "                    [\"The children are playing in the park near the river.\", \"Les enfants jouent dans le parc prÃ¨s de la riviÃ¨re.\", \"English\", \"French\", \"Intermediate (B1-B2)\"],\n",
        "                    [\"I would like to book a table for two people tonight.\", \"Je voudrais rÃ©server une table pour deux personnes ce soir.\", \"English\", \"French\", \"Beginner (A1-A2)\"],\n",
        "                ],\n",
        "                inputs=[trans_original, trans_student, trans_source_lang, trans_target_lang, trans_level]\n",
        "            )\n",
        "\n",
        "            trans_btn.click(\n",
        "                fn=translation_practice,\n",
        "                inputs=[trans_original, trans_student, trans_source_lang, trans_target_lang, trans_level],\n",
        "                outputs=[trans_output, trans_time]\n",
        "            )\n",
        "\n",
        "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "        # TAB 4: Vocabulary Builder\n",
        "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "        with gr.TabItem(\"ğŸ“š Vocabulary Builder\", id=4):\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### ğŸ“– Build Your Vocabulary by Topic\n",
        "            Choose any topic and get a complete vocabulary lesson with words,\n",
        "            sentences, phrases, and a quiz to test yourself.\n",
        "            \"\"\")\n",
        "\n",
        "            with gr.Row():\n",
        "                vocab_topic = gr.Textbox(\n",
        "                    label=\"Topic\",\n",
        "                    placeholder=\"e.g., Food, Travel, School, Weather, Technology...\",\n",
        "                    scale=2\n",
        "                )\n",
        "                vocab_lang = gr.Dropdown(\n",
        "                    choices=LANGUAGES,\n",
        "                    value=\"Swahili\",\n",
        "                    label=\"Target Language\",\n",
        "                    scale=1\n",
        "                )\n",
        "                vocab_level = gr.Dropdown(\n",
        "                    choices=PROFICIENCY_LEVELS,\n",
        "                    value=\"Beginner (A1-A2)\",\n",
        "                    label=\"Level\",\n",
        "                    scale=1\n",
        "                )\n",
        "\n",
        "            vocab_num = gr.Slider(\n",
        "                minimum=5, maximum=20, value=10, step=1,\n",
        "                label=\"Number of Words\"\n",
        "            )\n",
        "\n",
        "            vocab_btn = gr.Button(\"ğŸ“š Generate Lesson\", variant=\"primary\")\n",
        "            vocab_output = gr.Markdown(label=\"Vocabulary Lesson\")\n",
        "            vocab_time = gr.Textbox(label=\"Performance\", interactive=False)\n",
        "\n",
        "            gr.Examples(\n",
        "                examples=[\n",
        "                    [\"Food and Cooking\", \"Swahili\", \"Beginner (A1-A2)\"],\n",
        "                    [\"School and Education\", \"French\", \"Intermediate (B1-B2)\"],\n",
        "                    [\"Transportation\", \"Japanese\", \"Beginner (A1-A2)\"],\n",
        "                    [\"Family and Relationships\", \"Lingala\", \"Beginner (A1-A2)\"],\n",
        "                ],\n",
        "                inputs=[vocab_topic, vocab_lang, vocab_level]\n",
        "            )\n",
        "\n",
        "            vocab_btn.click(\n",
        "                fn=vocabulary_builder,\n",
        "                inputs=[vocab_topic, vocab_lang, vocab_level, vocab_num],\n",
        "                outputs=[vocab_output, vocab_time]\n",
        "            )\n",
        "\n",
        "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "        # TAB 5: Conversation Practice\n",
        "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "        with gr.TabItem(\"ğŸ’¬ Conversation Practice\", id=5):\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### ğŸ—£ï¸ Practice Real Conversations\n",
        "            Choose a scenario and chat with the AI in your target language.\n",
        "            You'll get corrections and tips after each message.\n",
        "            \"\"\")\n",
        "\n",
        "            with gr.Row():\n",
        "                convo_lang = gr.Dropdown(\n",
        "                    choices=LANGUAGES,\n",
        "                    value=\"French\",\n",
        "                    label=\"Practice Language\"\n",
        "                )\n",
        "                convo_level = gr.Dropdown(\n",
        "                    choices=PROFICIENCY_LEVELS,\n",
        "                    value=\"Beginner (A1-A2)\",\n",
        "                    label=\"Level\"\n",
        "                )\n",
        "                convo_scenario = gr.Dropdown(\n",
        "                    choices=[\n",
        "                        \"At a restaurant ordering food\",\n",
        "                        \"Asking for directions on the street\",\n",
        "                        \"Job interview at a tech company\",\n",
        "                        \"Meeting a new friend at school\",\n",
        "                        \"Shopping at a market\",\n",
        "                        \"Visiting a doctor\",\n",
        "                        \"Checking into a hotel\",\n",
        "                        \"At the train station buying tickets\",\n",
        "                    ],\n",
        "                    value=\"At a restaurant ordering food\",\n",
        "                    label=\"Conversation Scenario\"\n",
        "                )\n",
        "\n",
        "            convo_history = gr.State(value=\"\")  # Hidden state for chat history\n",
        "\n",
        "            convo_input = gr.Textbox(\n",
        "                label=\"Your Message\",\n",
        "                placeholder=\"Type in your target language... (e.g., 'Bonjour, je voudrais...')\",\n",
        "                lines=2\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                convo_btn = gr.Button(\"ğŸ’¬ Send Message\", variant=\"primary\")\n",
        "                convo_reset = gr.Button(\"ğŸ”„ New Conversation\", variant=\"secondary\")\n",
        "\n",
        "            convo_output = gr.Markdown(label=\"AI Response & Notes\")\n",
        "            convo_time = gr.Textbox(label=\"Performance\", interactive=False)\n",
        "\n",
        "            convo_btn.click(\n",
        "                fn=conversation_practice,\n",
        "                inputs=[convo_input, convo_scenario, convo_lang, convo_level, convo_history],\n",
        "                outputs=[convo_output, convo_history, convo_time]\n",
        "            )\n",
        "\n",
        "            # Reset conversation\n",
        "            convo_reset.click(\n",
        "                fn=lambda: (\"\", \"\", \"\"),\n",
        "                outputs=[convo_output, convo_history, convo_time]\n",
        "            )\n",
        "\n",
        "    # â”€â”€ Footer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    gr.Markdown(\"\"\"\n",
        "    ---\n",
        "    ### â„¹ï¸ About This Tool\n",
        "\n",
        "    **Mwalimu-LangLearn** (\"Mwalimu\" means \"Teacher\" in Swahili) is an AI-powered\n",
        "    language learning platform built with:\n",
        "    - ğŸ§  **Google Gemma 3n** (E2B-IT) â€” Compact multimodal AI model\n",
        "    - ğŸ–¼ï¸ **MobileNet-V5** vision encoder for image understanding\n",
        "    - ğŸŒ **140+ language** support for multilingual learning\n",
        "    - ğŸ¨ **Gradio** for interactive web interface\n",
        "\n",
        "    Built by **Pascal Burume Buhendwa** | ABE Initiative @ Kobe Institute of Computing\n",
        "\n",
        "    *Part of the Mwalimu-STEM-GenAI research project for AI-powered education in the DRC*\n",
        "    \"\"\")\n",
        "\n",
        "print(\"âœ… Gradio interface built successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcXKOMdbaQme"
      },
      "source": [
        "---\n",
        "## Step 8: Launch the Application\n",
        "\n",
        "Launch the Gradio app. On Kaggle, this creates a shareable public URL that lasts for the notebook session.\n",
        "\n",
        "**Key parameters:**\n",
        "- `share=True` â€” Creates a public URL (needed on Kaggle)\n",
        "- `server_name=\"0.0.0.0\"` â€” Listens on all interfaces\n",
        "- `server_port=7860` â€” Default Gradio port"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "MynimaLsaQme",
        "outputId": "c2253032-dfc9-4c33-d33a-f536d35b0b19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://fbfb48f8a47d5420cf.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://fbfb48f8a47d5420cf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ============================================================\n",
        "# STEP 8: Launch the Application\n",
        "# ============================================================\n",
        "\n",
        "# Launch with a shareable public link\n",
        "demo.launch(\n",
        "    share=True,           # Creates a public URL (required for Kaggle)\n",
        "    server_name=\"0.0.0.0\",\n",
        "    server_port=7860,\n",
        "    show_error=True,      # Show errors in the UI for debugging\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PahPeGjjaQme"
      },
      "source": [
        "---\n",
        "## ğŸ“‹ Summary: Step-by-Step Implementation Guide\n",
        "\n",
        "### What We Built:\n",
        "\n",
        "| Step | What | Why |\n",
        "|------|------|-----|\n",
        "| **1** | Install dependencies | Gemma 3n needs transformers â‰¥4.53.0, timm for vision |\n",
        "| **2** | Import libraries | Load all required modules |\n",
        "| **3** | Download & load model | Use kagglehub for Kaggle, or HuggingFace directly |\n",
        "| **4** | Core inference functions | `query_model()` for text, `query_model_with_image()` for multimodal |\n",
        "| **5** | Feature functions | 5 learning modes with specialized system prompts |\n",
        "| **6** | Test features | Verify each feature before building UI |\n",
        "| **7** | Build Gradio UI | 5-tab interface with examples and state management |\n",
        "| **8** | Launch app | Public URL for sharing |\n",
        "\n",
        "### How Gemma 3n Works Under the Hood:\n",
        "\n",
        "1. **Text Input** â†’ Tokenized by `AutoProcessor` â†’ Fed to language decoder\n",
        "2. **Image Input** â†’ Resized to 256/512/768px â†’ Encoded by MobileNet-V5 to 256 tokens â†’ Concatenated with text tokens\n",
        "3. **Generation** â†’ Autoregressive decoding with temperature sampling â†’ Decoded back to text\n",
        "\n",
        "### Key Technical Details:\n",
        "\n",
        "- **Chat Template**: Gemma 3n uses `<start_of_turn>user\\n...\\n<end_of_turn>` format\n",
        "- **System Prompt**: Set via `{\"role\": \"system\"}` message â€” controls the model's behavior\n",
        "- **Image Processing**: The processor handles all resizing and normalization\n",
        "- **`disable_compile=True`**: Required for Kaggle environments to avoid JIT compilation issues\n",
        "- **`device_map=\"auto\"`**: Automatically places model layers on available GPU(s)\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸš€ Next Steps for Enhancement:\n",
        "\n",
        "1. **Audio Input**: Gemma 3n supports audio (USM encoder) â€” add speech recognition for pronunciation practice\n",
        "2. **Fine-tuning**: Fine-tune on language learning datasets for better pedagogical responses\n",
        "3. **Offline Deployment**: Use LiteRT (TFLite) format for mobile/edge deployment\n",
        "4. **User Progress Tracking**: Add a database to track vocabulary mastery over time\n",
        "5. **Spaced Repetition**: Implement SRS (like Anki) for vocabulary review scheduling\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“š References\n",
        "\n",
        "- [Gemma 3n Model Card (Kaggle)](https://www.kaggle.com/models/google/gemma-3n)\n",
        "- [Gemma 3n on HuggingFace](https://huggingface.co/google/gemma-3n-E2B-it)\n",
        "- [How to use Gemma 3n on Kaggle (Paul Timothy Mooney)](https://www.kaggle.com/code/paultimothymooney/how-to-use-gemma-3n-on-kaggle)\n",
        "- [Gemma 3n Developer Guide (Google)](https://developers.googleblog.com/en/introducing-gemma-3n-developer-guide/)\n",
        "- [HuggingFace Gemma 3n Blog](https://huggingface.co/blog/gemma3n)\n",
        "- [Gradio Documentation](https://www.gradio.app/docs)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e890bedc1374d9eaee0e20cd1988103": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa12c01488ca4ee6ab5a0f477ee22bda",
              "IPY_MODEL_3e73829b68314933a9a154fca7421c9d",
              "IPY_MODEL_66d19f10f2384e28be0871acc706d56c"
            ],
            "layout": "IPY_MODEL_e433ee207e49447fb119fa7133c6fb35"
          }
        },
        "28100b74c4354e139030700278882d12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e73829b68314933a9a154fca7421c9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_552612e5f98d4ab18d8957a2a58af688",
            "max": 1556,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1347cac04434209b324469818494388",
            "value": 1556
          }
        },
        "43817df852e94b3ba04c80a1523e06bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "552612e5f98d4ab18d8957a2a58af688": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66d19f10f2384e28be0871acc706d56c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eb9927d561b41c785f0b9574afa1b41",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_28100b74c4354e139030700278882d12",
            "value": "â€‡1556/1556â€‡[00:43&lt;00:00,â€‡97.30it/s,â€‡Materializingâ€‡param=model.vision_tower.timm_model.msfa.norm.weight]"
          }
        },
        "6eb9927d561b41c785f0b9574afa1b41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa12c01488ca4ee6ab5a0f477ee22bda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c31c53ad4e9e464b95ebb2475276dc14",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_43817df852e94b3ba04c80a1523e06bf",
            "value": "Loadingâ€‡weights:â€‡100%"
          }
        },
        "c31c53ad4e9e464b95ebb2475276dc14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e433ee207e49447fb119fa7133c6fb35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1347cac04434209b324469818494388": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
